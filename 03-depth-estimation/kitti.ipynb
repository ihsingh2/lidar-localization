{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation of HD LiDAR Map using Depth Estimates from Depth Anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import open3d as o3d\n",
    "import scipy\n",
    "import trimesh\n",
    "import vdbfusion\n",
    "from tqdm import tqdm\n",
    "from trimesh import transform_points\n",
    "from vdbfusion import VDBVolume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Depth Estimation using Depth Anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python Depth-Anything/run.py --encoder vitb --img-path data/kitti-odometry/sequences/00/image_2 --outdir data/kitti-odometry/sequences/00/depth --pred-only --grayscale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creation of Local Point Clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_projection_matrix(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        for line in file:\n",
    "            if line.startswith(\"P2:\"):\n",
    "                p2_values = list(map(float, line.split()[1:]))\n",
    "                P = np.array(p2_values).reshape(3, 4)\n",
    "                return P\n",
    "\n",
    "def decompose_projection_matrix(P):\n",
    "    M = P[:, :3]\n",
    "    p = P[:, 3]\n",
    "    K, R = scipy.linalg.rq(M)\n",
    "    K /= K[2, 2]\n",
    "    t = np.linalg.inv(K) @ p\n",
    "    return K, R, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = read_projection_matrix('data/kitti-odometry/sequences/00/calib.txt')\n",
    "K, R, t = decompose_projection_matrix(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_projected_points(depth_image):\n",
    "    img = cv2.imread(depth_image, 0)\n",
    "\n",
    "    u, v = np.meshgrid(np.arange(img.shape[1]), np.arange(img.shape[0]))\n",
    "    u = u.flatten()\n",
    "    v = np.flipud(v.flatten())\n",
    "    depth = img.flatten()\n",
    "\n",
    "    u = u[depth > 0]\n",
    "    v = v[depth > 0]\n",
    "    depth = depth[depth > 0]\n",
    "\n",
    "    return np.stack((u * depth, v * depth, depth), axis=-1).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(100):\n",
    "    projected_points = get_projected_points(f'data/kitti-odometry/sequences/00/depth/{idx:06}_depth.png')\n",
    "    points = projected_points @ np.linalg.inv(K).T\n",
    "    points = (points - t) @ R\n",
    "    points = np.hstack([points, np.ones((points.shape[0], 1))]).astype(np.float32)\n",
    "    points.tofile(f'data/kitti-odometry/sequences/00/velodyne/{idx:06}.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pose Estimation using KISS-ICP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kiss_icp_pipeline --dataloader kitti --sequence 0 data/kitti-odometry/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dataloader for Transformed Point Clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrowed (with modifications) from VDBFusion, https://github.com/PRBonn/vdbfusion/blob/main/examples/notebooks/kitti_odometry.ipynb, subject to the following terms.\n",
    "\n",
    "# MIT License\n",
    "\n",
    "# Copyright (c) 2022 Ignacio Vizzo, Cyrill Stachniss, University of Bonn\n",
    "\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "\n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    "\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "# SOFTWARE.\n",
    "\n",
    "class Config:\n",
    "    # Data specific params\n",
    "    apply_pose = True\n",
    "    min_range = 2.0\n",
    "    max_range = 70.0\n",
    "\n",
    "\n",
    "class KITTIOdometryDataset:\n",
    "    def __init__(self, kitti_root_dir: str, sequence: int, pose_estimate: Optional[str] = None):\n",
    "        \"\"\"Simple KITTI DataLoader to provide a ready-to-run example.\n",
    "\n",
    "        Heavily inspired in PyLidar SLAM\n",
    "        \"\"\"\n",
    "        # Config stuff\n",
    "        self.sequence = str(int(sequence)).zfill(2)\n",
    "        self.config = Config()\n",
    "        self.kitti_sequence_dir = os.path.join(kitti_root_dir, \"sequences\", self.sequence)\n",
    "        self.velodyne_dir = os.path.join(self.kitti_sequence_dir, \"velodyne/\")\n",
    "\n",
    "        # Read stuff\n",
    "        self.calibration = self.read_calib_file(os.path.join(self.kitti_sequence_dir, \"calib.txt\"))\n",
    "        if pose_estimate is None:\n",
    "            self.poses = self.load_poses(os.path.join(kitti_root_dir, f\"poses/{self.sequence}.txt\"))\n",
    "        else:\n",
    "            self.poses = np.load(pose_estimate)\n",
    "            self.poses = self._lidar_pose_gt(self.poses)\n",
    "        self.scan_files = sorted(glob.glob(self.velodyne_dir + \"*.bin\"))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.scans(idx), self.poses[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.scan_files)\n",
    "\n",
    "    def scans(self, idx):\n",
    "        return self.read_point_cloud(idx, self.scan_files[idx], self.config)\n",
    "\n",
    "    def read_point_cloud(self, idx: int, scan_file: str, config: Config):\n",
    "        points = np.fromfile(scan_file, dtype=np.float32).reshape((-1, 4))[:, :-1]\n",
    "        points = points[np.linalg.norm(points, axis=1) <= config.max_range]\n",
    "        points = points[np.linalg.norm(points, axis=1) >= config.min_range]\n",
    "        points = transform_points(points, self.poses[idx]) if config.apply_pose else points\n",
    "        return points\n",
    "\n",
    "    def load_poses(self, poses_file):\n",
    "        poses = pd.read_csv(poses_file, sep=\" \", header=None).values\n",
    "        n = poses.shape[0]\n",
    "        poses = np.concatenate(\n",
    "            (poses, np.zeros((n, 3), dtype=np.float32), np.ones((n, 1), dtype=np.float32)), axis=1\n",
    "        )\n",
    "        poses = poses.reshape((n, 4, 4))  # [N, 4, 4]\n",
    "        return self._lidar_pose_gt(poses)\n",
    "\n",
    "    def _lidar_pose_gt(self, poses_gt):\n",
    "        _tr = self.calibration[\"Tr\"].reshape(3, 4)\n",
    "        tr = np.eye(4, dtype=np.float64)\n",
    "        tr[:3, :4] = _tr\n",
    "        left = np.einsum(\"...ij,...jk->...ik\", np.linalg.inv(tr), poses_gt)\n",
    "        right = np.einsum(\"...ij,...jk->...ik\", left, tr)\n",
    "        return right\n",
    "\n",
    "    @staticmethod\n",
    "    def read_calib_file(file_path: str) -> dict:\n",
    "        calib_dict = {}\n",
    "        with open(file_path, \"r\") as calib_file:\n",
    "            for line in calib_file.readlines():\n",
    "                tokens = line.split(\" \")\n",
    "                if tokens[0] == \"calib_time:\":\n",
    "                    continue\n",
    "                # Only read with float data\n",
    "                if len(tokens) > 0:\n",
    "                    values = [float(token) for token in tokens[1:]]\n",
    "                    values = np.array(values, dtype=np.float32)\n",
    "                    # The format in KITTI's file is <key>: <f1> <f2> <f3> ...\\n -> Remove the ':'\n",
    "                    key = tokens[0][:-1]\n",
    "                    calib_dict[key] = values\n",
    "        return calib_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generation of LiDAR Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = KITTIOdometryDataset(kitti_root_dir='data/kitti-odometry/', sequence=0, \\\n",
    "                                                    pose_estimate='results/latest/00_poses.npy')\n",
    "\n",
    "points = []\n",
    "for scan, pose in tqdm(dataset):\n",
    "    points.append(scan)\n",
    "\n",
    "points = np.vstack(points)\n",
    "points.tofile('data/kitti-odometry/map/map.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization of LiDAR Map, integrated through VDBFusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdb_volume = VDBVolume(voxel_size=0.1, sdf_trunc=0.3, space_carving=False)\n",
    "for scan, pose in tqdm(dataset):\n",
    "    vdb_volume.integrate(scan, pose)\n",
    "\n",
    "vertices, triangles = vdb_volume.extract_triangle_mesh(fill_holes=True, min_weight=5.0)\n",
    "mesh = trimesh.Trimesh(vertices=vertices, faces=triangles)\n",
    "mesh.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
